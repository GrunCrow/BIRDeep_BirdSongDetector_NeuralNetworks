{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Mel Spectrograms from Audio Files ðŸŽµ\n",
    "\n",
    "This notebook converts audio files into Mel spectrogram images, which visually represent the frequency content of sounds over time. These spectrograms can be used for machine learning tasks such as birdsong classification. We will use this images for training other deep learning architectures as bird vocalization classifiers.\n",
    "\n",
    "The script processes audio files, ensuring they are at least 3 seconds long by padding shorter clips and splitting longer ones into 3-second segments. Each segment is then transformed into a Mel spectrogram and saved as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"../../Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(audio_file):\n",
    "    fmin = 0  # Minimum frequency (0 Hz)\n",
    "    fmax = 16000  # Maximum frequency (16 kHz)\n",
    "    \n",
    "    # Load audio\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    \n",
    "    # Make lowercase uppercase\n",
    "    if audio_file.endswith(\".wav\"):\n",
    "        audio_file = audio_file.replace(\".wav\", \".WAV\")\n",
    "\n",
    "    # Define output directory\n",
    "    output_image_dir = audio_file.replace('Audios', 'images').rsplit('/', 1)[0]\n",
    "    os.makedirs(output_image_dir, exist_ok=True)  # Crear solo una vez\n",
    "\n",
    "    # define SFTF\n",
    "    D = librosa.amplitude_to_db(librosa.stft(y), ref=np.max)  # Solo calcular STFT una vez\n",
    "\n",
    "    # If audio os shorter than 3 seconds, pad it\n",
    "    if len(y) < 3 * sr:\n",
    "        y = np.pad(y, (0, 3 * sr - len(y)), mode='constant')  # Padding al final\n",
    "        output_image_path = audio_file.replace('Audios', 'images').replace(\".WAV\", \".PNG\")\n",
    "        save_spectrogram(D, sr, fmin, fmax, output_image_path)\n",
    "\n",
    "    # If audio is greater than 3 seconds, iterate in 3 seconds\n",
    "    else:\n",
    "        for i in range(0, len(y), 3 * sr):  # Iterate in 3 seconds\n",
    "            y_clip = y[i:i + 3 * sr]\n",
    "            if len(y_clip) < 3 * sr:\n",
    "                y_clip = np.pad(y_clip, (0, 3 * sr - len(y_clip)), mode='constant')  # Padding\n",
    "\n",
    "            output_image_path = audio_file.replace('Audios', 'images').replace(\".WAV\", f\"_{i//(3*sr)}.PNG\")\n",
    "            save_spectrogram(D[:, i//(3*sr):(i//(3*sr)+1)], sr, fmin, fmax, output_image_path)\n",
    "\n",
    "def save_spectrogram(D, sr, fmin, fmax, output_path):\n",
    "    \"\"\"Generates and saves a spectrogram\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    librosa.display.specshow(D, sr=sr, x_axis=\"time\", y_axis=\"log\", fmin=fmin, fmax=fmax, ax=ax)\n",
    "    ax.axis('off')  # Eliminate axis\n",
    "    fig.savefig(output_path, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    plt.close(fig)  # Close figure - save memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3701780/1972752217.py:17: UserWarning: amplitude_to_db was called on complex input so phase information will be discarded. To suppress this warning, call amplitude_to_db(np.abs(S)) instead.\n",
      "  D = librosa.amplitude_to_db(librosa.stft(y), ref=np.max)  # Solo calcular STFT una vez\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Spectrograms generated succesfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATASET_FOLDER = ROOT_PATH + \"Dataset/Audios/For Classifier/train\"\n",
    "\n",
    "# Recorrer todos los subdirectorios y archivos de audio\n",
    "for root, _, files in os.walk(DATASET_FOLDER):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.wav'):  # Asegura que detecte '.WAV' y '.wav'\n",
    "            audio_file = os.path.join(root, file)\n",
    "            output_image_path = audio_file.replace('Audios', 'images').replace(\".WAV\", \".PNG\").replace(\".wav\", \".PNG\")\n",
    "\n",
    "            if not os.path.exists(output_image_path):  # Omitir si la imagen ya existe\n",
    "                try:\n",
    "                    create_spectrogram(audio_file)\n",
    "                    # print(f\"âœ… Generated Spectrogram: {output_image_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Error processing {audio_file}: {e}\")\n",
    "\n",
    "print(\"ðŸŽ‰ Spectrograms generated succesfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of audio files: 3111\n",
      "Number of image files: 7469\n"
     ]
    }
   ],
   "source": [
    "DATASET_FOLDER = ROOT_PATH + \"Dataset/Audios/For Classifier/\"\n",
    "\n",
    "# Count number of .WAV files in Dataset Folder and Count number of .PNG files in Images Folder\n",
    "audio_files = sum([len(files) for _, _, files in os.walk(DATASET_FOLDER)])\n",
    "image_files = sum([len(files) for _, _, files in os.walk(DATASET_FOLDER.replace('Audios', 'images'))])\n",
    "\n",
    "print(f\"Number of audio files: {audio_files}\")\n",
    "print(f\"Number of image files: {image_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more images than audio files because there are segments that are longer than 3 seconds and images have to be 3 seconds long."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIRDeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
